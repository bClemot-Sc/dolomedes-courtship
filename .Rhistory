dn <- data_names[i]
data <- unlist(subset(df, condition == con)[,dt], use.names = FALSE)
plot_list[[k]] <- plot_circle(data, N_bin, pt_width, r_spacing) +
ggtitle(paste(con, " - ", dn, " (n=", length(data), ")")) +
theme(plot.title = element_text(face = "bold", hjust = 0.5))
k <- k+1
}
}
# Plot the grid
x11()
do.call(grid.arrange, c(plot_list, ncol = 3, nrow = 4))
# Plot the grid
do.call(grid.arrange, c(plot_list, ncol = 3, nrow = 4))
# Load packages
library(ggplot2)
library(gridExtra)
library(bootstrap)
library(tidyverse)
install.packages(tidyverse)
install.packages('tidyverse')
# Load packages
library(ggplot2)
library(gridExtra)
library(bootstrap)
library(tidyverse)
# Load packages
library(ggplot2)
library(gridExtra)
library(bootstrap)
library(tidyverse)
# Load necessary library
library(dplyr)
# Define paths
data_folder <- "/home/sc-bclemot/Documents/ArenaSizeExperiment/data_processed"
output_file <- "/home/sc-bclemot/Documents/ArenaSizeExperiment/merged_data.rds"
# Get all CSV files in the data folder
csv_files <- list.files(data_folder, pattern = "\\.csv$", full.names = TRUE)
# Read all CSV files into a list of data frames
data_list <- lapply(csv_files, read.csv)
View(data_list)
source("~/Documents/ArenaSizeExperiment/data_analysis/arena_size_analysis.R", echo=TRUE)
rm(csv_files)
# Libraries and Data -------------------------------------------------------
# Import libraries
library(dplyr)
# Get tracking CSV files
data_folder <- "/home/sc-bclemot/Documents/ArenaSizeExperiment/data_processed"
csv_files <- list.files(data_folder, pattern = "\\.csv$", full.names = TRUE)
data_list <- lapply(csv_files, read.csv)
rm(csv_files)
rm(data_folder)
# Import libraries
library(dplyr)
# Get tracking CSV files
data_folder <- "/home/sc-bclemot/Documents/ArenaSizeExperiment/data_processed"
csv_files <- list.files(data_folder, pattern = "\\.csv$", full.names = TRUE)
data_list <- lapply(csv_files, read.csv)
rm(csv_files)
rm(data_folder)
install.packages("circular")  # if not already installed
library(circular)
circular_dispersion_permutation_test <- function(angles, groups, n_perm = 10000, stat = "range") {
if (!requireNamespace("circular", quietly = TRUE)) {
stop("The 'circular' package is required.")
}
# Ensure angles are in circular format
angles <- circular::circular(angles, units = "radians", modulo = "2pi")
# Compute group concentrations
get_rbar <- function(g) {
circular::rho.circular(g)
}
rbar_by_group <- tapply(angles, groups, get_rbar)
# Statistic to compare: range or variance of R̄s
observed_stat <- switch(stat,
"range" = max(rbar_by_group) - min(rbar_by_group),
"var" = var(rbar_by_group),
stop("Invalid 'stat' argument. Use 'range' or 'var'.")
)
# Permutation test
perm_stats <- replicate(n_perm, {
shuffled_groups <- sample(groups)
rbar_shuffled <- tapply(angles, shuffled_groups, get_rbar)
switch(stat,
"range" = max(rbar_shuffled) - min(rbar_shuffled),
"var" = var(rbar_shuffled)
)
})
# Two-sided p-value
p_value <- mean(perm_stats >= observed_stat)
# Return result
list(
observed_statistic = observed_stat,
p_value = p_value,
perm_distribution = perm_stats,
rbar_by_group = rbar_by_group
)
}
library(circular)
# Simulated example: 3 groups with different concentrations
set.seed(123)
angles <- c(
rvonmises(20, mu = circular(0), kappa = 2),   # Group A: low concentration
rvonmises(20, mu = circular(0), kappa = 5),   # Group B: higher concentration
rvonmises(20, mu = circular(0), kappa = 10)   # Group C: very concentrated
)
groups <- factor(rep(c("A", "B", "C"), each = 20))
# Run test
result <- circular_dispersion_permutation_test(angles, groups, n_perm = 5000)
# View results
result$p_value
result$observed_statistic
result$rbar_by_group
# Optional: visualize permutation distribution
hist(result$perm_distribution, breaks = 50,
main = "Permutation Distribution of Dispersion Statistic",
xlab = "Max(R̄) - Min(R̄)")
abline(v = result$observed_statistic, col = "red", lwd = 2)
angles
groups
# View results
result$p_value
result$observed_statistic
read_behavior_data <- function(file_name, group, path) {
read_csv(
file.path(path, paste0(file_name, ".csv")),
show_col_types = FALSE,
name_repair = "minimal"
) %>%
select(-1) %>%
mutate(
File = file_name,
Group = group,
Duration = as.numeric(Duration)
) %>%
filter(!is.na(Duration))
}
# Packages
library(tidyverse)
library(dplyr)
library(readr)
library(purrr)
library(stringr)
files_g1 <- c(
"Aggregated_G26xJ203", "Aggregated_G30xJ210", "Aggregated_H30xH71",
"Aggregated_H45xH65", "Aggregated_H62xJ132", "Aggregated_J101xJ204",
"Aggregated_J102xJ206", "Aggregated_J110xH67", "Aggregated_J124xG42",
"Aggregated_J144xG39", "Aggregated_J183xH26", "Aggregated_J189xJ112",
"Aggregated_J190xJ42", "Aggregated_J191xJ68", "Aggregated_J201xG43"
)
files_g2 <- c(
"Aggregated_G30xH52", "Aggregated_H30xG38", "Aggregated_H62xG33",
"Aggregated_J101xH76", "Aggregated_J102xJ161", "Aggregated_J110xJ140",
"Aggregated_J124xG32", "Aggregated_J144xG38", "Aggregated_J183xG35",
"Aggregated_J190xJ212"
)
path_g1 <- "data_scoring/unmated"
path_g2 <- "data_scoring/mated"
data_g1 <- map_dfr(files_g1, read_behavior_data, group = "unmated", path = path_g1)
behaviour_stats_wide <- behaviour_stats %>%
pivot_wider(
names_from = Group,
values_from = c(MeanTimeFreq, SETimeFreq, N),
names_sep = "_"
)
View(final_results)
discrete_behaviours <- c("Abdomen Tapping", "Retreat")
# Count occurrences
discrete_counts <- full_data %>%
filter(Behaviour %in% discrete_behaviours) %>%
group_by(Group, File, Behaviour) %>%
summarise(Occurrences = n(), .groups = "drop") %>%
mutate(ID = str_extract(File, "(?<=Aggregated_)[^x]+"))
# Summary stats per group
discrete_stats <- discrete_counts %>%
group_by(Group, Behaviour) %>%
summarise(
MeanOccurrences = mean(Occurrences),
SEOccurrences = sd(Occurrences) / sqrt(n()),
N = n(),
.groups = "drop"
)
# Pivot to wide for paired test
discrete_wide <- discrete_counts %>%
select(ID, Group, Behaviour, Occurrences) %>%
pivot_wider(names_from = Group, values_from = Occurrences)
# Wilcoxon paired test
discrete_wilcoxon <- discrete_wide %>%
group_by(Behaviour) %>%
summarise(
p_value = if (sum(!is.na(unmated) & !is.na(mated)) >= 3) {
wilcox.test(unmated, mated, paired = TRUE, exact = FALSE)$p.value
} else { NA_real_ },
statistic = if (sum(!is.na(unmated) & !is.na(mated)) >= 3) {
wilcox.test(unmated, mated, paired = TRUE, exact = FALSE)$statistic
} else { NA_real_ },
.groups = "drop"
)
# Final results for discrete behaviours
discrete_results <- discrete_stats %>%
pivot_wider(
names_from = Group,
values_from = c(MeanOccurrences, SEOccurrences, N),
names_sep = "_"
) %>%
left_join(discrete_wilcoxon, by = "Behaviour") %>%
select(
Behaviour,
MeanOccurrences_unmated, SEOccurrences_unmated, N_unmated,
MeanOccurrences_mated, SEOccurrences_mated, N_mated,
statistic, p_value
)
View(discrete_results)
read_behavior_data <- function(file_name, group, path) {
read_csv(
file.path(path, paste0(file_name, ".csv")),
show_col_types = FALSE,
name_repair = "minimal"
) %>%
select(-1) %>%
mutate(
File = file_name,
Group = group,
Duration = as.numeric(Duration)
) %>%
filter(!is.na(Duration))
}
# Packages
library(tidyverse)
library(dplyr)
library(readr)
library(purrr)
library(stringr)
files_g1 <- c(
"Aggregated_G26xJ203", "Aggregated_G30xJ210", "Aggregated_H30xH71",
"Aggregated_H45xH65", "Aggregated_H62xJ132", "Aggregated_J101xJ204",
"Aggregated_J102xJ206", "Aggregated_J110xH67", "Aggregated_J124xG42",
"Aggregated_J144xG39", "Aggregated_J183xH26", "Aggregated_J189xJ112",
"Aggregated_J190xJ42", "Aggregated_J191xJ68", "Aggregated_J201xG43"
)
files_g2 <- c(
"Aggregated_G30xH52", "Aggregated_H30xG38", "Aggregated_H62xG33",
"Aggregated_J101xH76", "Aggregated_J102xJ161", "Aggregated_J110xJ140",
"Aggregated_J124xG32", "Aggregated_J144xG38", "Aggregated_J183xG35",
"Aggregated_J190xJ212"
)
path_g1 <- "data_scoring/unmated"
path_g2 <- "data_scoring/mated"
data_g1 <- map_dfr(files_g1, read_behavior_data, group = "unmated", path = path_g1)
full_data <- bind_rows(data_g1, data_g2)
base_behaviours <- c("Abdomen Tapping", "Courtship.Start", "Freezing", "Leg Showcase",
"Mounted", "Pedipalp Showcase", "Mounting.Start", "Retreat", "Grooming")
all_combinations <- full_data %>%
distinct(Group, File) %>%
crossing(Behaviour = base_behaviours)
behaviour_time_summary <- full_data %>%
group_by(Group, File, Behaviour) %>%
summarise(TotalBehaviourTime = sum(Duration), .groups = "drop")
behaviour_time_complete <- all_combinations %>%
left_join(behaviour_time_summary, by = c("Group", "File", "Behaviour")) %>%
mutate(TotalBehaviourTime = replace_na(TotalBehaviourTime, 0))
total_time_per_file <- full_data %>%
group_by(Group, File) %>%
summarise(TotalTime = sum(Duration), .groups = "drop")
behaviour_time_complete <- behaviour_time_complete %>%
left_join(total_time_per_file, by = c("Group", "File")) %>%
mutate(TimeFrequency = TotalBehaviourTime / TotalTime)
behaviour_summary <- full_data %>%
group_by(Group, File, Behaviour) %>%
summarise(TotalBehaviourTime = sum(Duration), .groups = "drop") %>%
left_join(
full_data %>%
group_by(Group, File) %>%
summarise(TotalTime = sum(Duration), .groups = "drop"),
by = c("Group", "File")
) %>%
mutate(TimeFrequency = TotalBehaviourTime / TotalTime)
global_behaviours_summary <- bind_rows(
lapply(base_behaviours, function(bhvr) {
full_data %>%
filter(str_detect(Behaviour, fixed(bhvr))) %>%  # any behaviour that contains this string
group_by(Group, File) %>%
summarise(TotalBehaviourTime = sum(Duration), .groups = "drop") %>%
left_join(
full_data %>%
group_by(Group, File) %>%
summarise(TotalTime = sum(Duration), .groups = "drop"),
by = c("Group", "File")
) %>%
mutate(
Behaviour = paste(bhvr, "global"),
TimeFrequency = TotalBehaviourTime / TotalTime
) %>%
select(Group, File, Behaviour, TotalBehaviourTime, TotalTime, TimeFrequency)
})
)
combined_summary <- bind_rows(behaviour_summary, global_behaviours_summary)
behaviour_stats <- combined_summary %>%
group_by(Group, Behaviour) %>%
summarise(
MeanTimeFreq = mean(TimeFrequency),
SETimeFreq = sd(TimeFrequency) / sqrt(n()),
N = n(),
.groups = "drop"
)
# Extract individual ID (shared across groups) from filename
combined_summary <- combined_summary %>%
mutate(ID = str_extract(File, "(?<=Aggregated_)[^x]+"))
# Wide format for paired testing
behaviour_wide <- combined_summary %>%
select(ID, Group, Behaviour, TimeFrequency) %>%
pivot_wider(names_from = Group, values_from = TimeFrequency)
# Wilcoxon paired test per behaviour
wilcoxon_results <- behaviour_wide %>%
group_by(Behaviour) %>%
summarise(
p_value = if (sum(!is.na(unmated) & !is.na(mated)) >= 3) {
wilcox.test(unmated, mated, paired = TRUE, exact = FALSE)$p.value
} else { NA_real_ },
statistic = if (sum(!is.na(unmated) & !is.na(mated)) >= 3) {
wilcox.test(unmated, mated, paired = TRUE, exact = FALSE)$statistic
} else { NA_real_ },
.groups = "drop"
)
setwd("~/Documents/GitHub/dolomedes-courtship")
read_behavior_data <- function(file_name, group, path) {
read_csv(
file.path(path, paste0(file_name, ".csv")),
show_col_types = FALSE,
name_repair = "minimal"
) %>%
select(-1) %>%
mutate(
File = file_name,
Group = group,
Duration = as.numeric(Duration)
) %>%
filter(!is.na(Duration))
}
# Packages
library(tidyverse)
library(dplyr)
library(readr)
library(purrr)
library(stringr)
files_g1 <- c(
"Aggregated_G26xJ203", "Aggregated_G30xJ210", "Aggregated_H30xH71",
"Aggregated_H45xH65", "Aggregated_H62xJ132", "Aggregated_J101xJ204",
"Aggregated_J102xJ206", "Aggregated_J110xH67", "Aggregated_J124xG42",
"Aggregated_J144xG39", "Aggregated_J183xH26", "Aggregated_J189xJ112",
"Aggregated_J190xJ42", "Aggregated_J191xJ68", "Aggregated_J201xG43"
)
files_g2 <- c(
"Aggregated_G30xH52", "Aggregated_H30xG38", "Aggregated_H62xG33",
"Aggregated_J101xH76", "Aggregated_J102xJ161", "Aggregated_J110xJ140",
"Aggregated_J124xG32", "Aggregated_J144xG38", "Aggregated_J183xG35",
"Aggregated_J190xJ212"
)
path_g1 <- "data_scoring/unmated"
path_g2 <- "data_scoring/mated"
data_g1 <- map_dfr(files_g1, read_behavior_data, group = "unmated", path = path_g1)
data_g2 <- map_dfr(files_g2, read_behavior_data, group = "mated", path = path_g2)
full_data <- bind_rows(data_g1, data_g2)
base_behaviours <- c("Abdomen Tapping", "Courtship.Start", "Freezing", "Leg Showcase",
"Mounted", "Pedipalp Showcase", "Mounting.Start", "Retreat", "Grooming")
all_combinations <- full_data %>%
distinct(Group, File) %>%
crossing(Behaviour = base_behaviours)
behaviour_time_summary <- full_data %>%
group_by(Group, File, Behaviour) %>%
summarise(TotalBehaviourTime = sum(Duration), .groups = "drop")
behaviour_time_complete <- all_combinations %>%
left_join(behaviour_time_summary, by = c("Group", "File", "Behaviour")) %>%
mutate(TotalBehaviourTime = replace_na(TotalBehaviourTime, 0))
total_time_per_file <- full_data %>%
group_by(Group, File) %>%
summarise(TotalTime = sum(Duration), .groups = "drop")
behaviour_time_complete <- behaviour_time_complete %>%
left_join(total_time_per_file, by = c("Group", "File")) %>%
mutate(TimeFrequency = TotalBehaviourTime / TotalTime)
behaviour_summary <- full_data %>%
group_by(Group, File, Behaviour) %>%
summarise(TotalBehaviourTime = sum(Duration), .groups = "drop") %>%
left_join(
full_data %>%
group_by(Group, File) %>%
summarise(TotalTime = sum(Duration), .groups = "drop"),
by = c("Group", "File")
) %>%
mutate(TimeFrequency = TotalBehaviourTime / TotalTime)
global_behaviours_summary <- bind_rows(
lapply(base_behaviours, function(bhvr) {
full_data %>%
filter(str_detect(Behaviour, fixed(bhvr))) %>%  # any behaviour that contains this string
group_by(Group, File) %>%
summarise(TotalBehaviourTime = sum(Duration), .groups = "drop") %>%
left_join(
full_data %>%
group_by(Group, File) %>%
summarise(TotalTime = sum(Duration), .groups = "drop"),
by = c("Group", "File")
) %>%
mutate(
Behaviour = paste(bhvr, "global"),
TimeFrequency = TotalBehaviourTime / TotalTime
) %>%
select(Group, File, Behaviour, TotalBehaviourTime, TotalTime, TimeFrequency)
})
)
combined_summary <- bind_rows(behaviour_summary, global_behaviours_summary)
behaviour_stats <- combined_summary %>%
group_by(Group, Behaviour) %>%
summarise(
MeanTimeFreq = mean(TimeFrequency),
SETimeFreq = sd(TimeFrequency) / sqrt(n()),
N = n(),
.groups = "drop"
)
# Extract individual ID (shared across groups) from filename
combined_summary <- combined_summary %>%
mutate(ID = str_extract(File, "(?<=Aggregated_)[^x]+"))
# Wide format for paired testing
behaviour_wide <- combined_summary %>%
select(ID, Group, Behaviour, TimeFrequency) %>%
pivot_wider(names_from = Group, values_from = TimeFrequency)
# Wilcoxon paired test per behaviour
wilcoxon_results <- behaviour_wide %>%
group_by(Behaviour) %>%
summarise(
p_value = if (sum(!is.na(unmated) & !is.na(mated)) >= 3) {
wilcox.test(unmated, mated, paired = TRUE, exact = FALSE)$p.value
} else { NA_real_ },
statistic = if (sum(!is.na(unmated) & !is.na(mated)) >= 3) {
wilcox.test(unmated, mated, paired = TRUE, exact = FALSE)$statistic
} else { NA_real_ },
.groups = "drop"
)
behaviour_stats_wide <- behaviour_stats %>%
pivot_wider(
names_from = Group,
values_from = c(MeanTimeFreq, SETimeFreq, N),
names_sep = "_"
)
# Add percent values
final_results <- behaviour_stats_wide %>%
mutate(
MeanTimeFreq_unmated_pct = round(MeanTimeFreq_unmated * 100, 3),
MeanTimeFreq_mated_pct   = round(MeanTimeFreq_mated * 100, 3),
SETimeFreq_unmated_pct   = round(SETimeFreq_unmated * 100, 3),
SETimeFreq_mated_pct     = round(SETimeFreq_mated * 100, 3)
) %>%
left_join(wilcoxon_results, by = "Behaviour") %>%
select(
Behaviour,
MeanTimeFreq_unmated, SETimeFreq_unmated, N_unmated,
MeanTimeFreq_mated, SETimeFreq_mated, N_mated,
MeanTimeFreq_unmated_pct, SETimeFreq_unmated_pct,
MeanTimeFreq_mated_pct, SETimeFreq_mated_pct,
statistic, p_value
)
View(final_results)
discrete_behaviours <- c("Abdomen Tapping", "Retreat")
# Count occurrences
discrete_counts <- full_data %>%
filter(Behaviour %in% discrete_behaviours) %>%
group_by(Group, File, Behaviour) %>%
summarise(Occurrences = n(), .groups = "drop") %>%
mutate(ID = str_extract(File, "(?<=Aggregated_)[^x]+"))
# Summary stats per group
discrete_stats <- discrete_counts %>%
group_by(Group, Behaviour) %>%
summarise(
MeanOccurrences = mean(Occurrences),
SEOccurrences = sd(Occurrences) / sqrt(n()),
N = n(),
.groups = "drop"
)
# Pivot to wide for paired test
discrete_wide <- discrete_counts %>%
select(ID, Group, Behaviour, Occurrences) %>%
pivot_wider(names_from = Group, values_from = Occurrences)
# Wilcoxon paired test
discrete_wilcoxon <- discrete_wide %>%
group_by(Behaviour) %>%
summarise(
p_value = if (sum(!is.na(unmated) & !is.na(mated)) >= 3) {
wilcox.test(unmated, mated, paired = TRUE, exact = FALSE)$p.value
} else { NA_real_ },
statistic = if (sum(!is.na(unmated) & !is.na(mated)) >= 3) {
wilcox.test(unmated, mated, paired = TRUE, exact = FALSE)$statistic
} else { NA_real_ },
.groups = "drop"
)
# Final results for discrete behaviours
discrete_results <- discrete_stats %>%
pivot_wider(
names_from = Group,
values_from = c(MeanOccurrences, SEOccurrences, N),
names_sep = "_"
) %>%
left_join(discrete_wilcoxon, by = "Behaviour") %>%
select(
Behaviour,
MeanOccurrences_unmated, SEOccurrences_unmated, N_unmated,
MeanOccurrences_mated, SEOccurrences_mated, N_mated,
statistic, p_value
)
View(discrete_results)
final_results$MeanTimeFreq_mated_pct
final_results$MeanTimeFreq_unmated_pct
final_results$MeanTimeFreq_unmated_pct[-c(1,2,3,4,6,14,17,18,19,21,22,23)]
final_results$MeanTimeFreq_unmated_pct[-c(1,2,3,4,6,9,14,17,18,19,21,22,23)]
final_results$MeanTimeFreq_mated_pct[-c(1,2,3,4,6,9,14,17,18,19,21,22,23)]
